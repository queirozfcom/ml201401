#!/usr/bin/env python

# File partioning utility
# partitions the target file into training and testing set
# and then creates a directory for the contents.
# the partition files will be created under directory ./partitions/

from helpers.files import file_len,is_header
from string import replace
import math
import random
import sys
import os
import time

if len(sys.argv) < 2:
    print "\nERROR:Please provide the target files containing the data.\n\n"
    sys.exit()

#training set is twice as large as test set

file_name = str(sys.argv[1])

num_lines = file_len(file_name)

train_set_size = math.trunc((num_lines/3)*2)

test_set_size = math.trunc((num_lines/3))

# need all lines in a single place in order to manipulate them
with open(file_name) as f:
    all_lines = f.readlines()

# we should get a different set each time we run this script.
random.shuffle(all_lines)

train_set = list()
test_set  = list()

header = None 

for idx,line in enumerate(all_lines):
    if is_header(line): 
        header = line
    else:
        if idx <= train_set_size:
            train_set.append(line)
        else:
            test_set.append(line)
    

if header is not None:
    train_set.insert(0,header)
    test_set.insert(0,header)


#need a unique name for the directory where i'll keep the generated partitions.

current_dir = os.path.dirname(os.path.realpath(__file__))

base=os.path.basename(file_name)

clean_file_name = os.path.splitext(base)[0]

partitions_directory = current_dir+'/partitions/'+clean_file_name+'___'+replace(str(time.time()),'.','')[5:]

os.mkdir(partitions_directory)


#we need both train and test sets.

f = open(partitions_directory+'/train_set', 'w')

for line in iter(train_set):
    f.write(line)

f.close()

f = open(partitions_directory+'/test_set', 'w')

for line in iter(test_set):
    f.write(line)

f.close()

#file has been partitioned and is now in a directory under partitions/